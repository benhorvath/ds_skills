---
title: "DATA 607---Data Science Job Skills"
author: "Joel & Ben"
date: "October 14, 2018"
output:
  html_document:
    toc: true
---
  
```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load libraries:

```{r, warning=FALSE, message=FALSE}
library(dplyr)
library(ggplot2)
library(stringr)
library(tidyr)
```

# Introduction





# Data Collection

Approximately 500 data scientist positions were scraped from Indeed.com, spread between five large American cities: New York City, San Francisco, Chicago, Washington, D.C., and Seattle.

Indeed.com was chosen because of it's simple and clear query string method. _EXPAIN MORE_

Although the individual job listings were not as structured as we would like, we were able to put some structure to it. Our final data frame had columns: url, job title, company name, Indeed users' score of the comapny, job description, how long the posting had been up, metadata (often salary information), the date of scraping, city, and page number of results. 

The actual scrape algorithm is pretty simple blah blah blah:

1. For each `city` in the list of `cities`:
    1. Get some page of results, ` seq(0, 100, 10) = (0, 10, 20, ..., 100)`.
    2. For each `page` in `pages`:
        1. Assemble a URL of job results, e.g., ` https://www.indeed.com/jobs?q=data+scientist&l=Seattle%2C+WA&start=100`
        2. Read the HTML of the resulting page: `read_html(results_url)`
        3. Extract the approximately 15 links for job postings contained in the HTML: `extract_listing_urls(results_page_html)`
        4. Use `sapply` to `extract_listing_data()` from each of these links
        5. Transforming these results into a data.frame, save it to a TSV file
        
**GO INTO `extract_listing_urls()` and `extract_listing_data()` IN MORE DEPTH HERE** particularly noting the `tryCatch` wrapping technique

Challenge: Saving long stings of text in CSV format. Got around it by 1. using TSV
instead of CSV, 2. replacing all whitespace characters like `\n` and `\t` with simple spaces, and 3. using `stringr::str_squish`. In retrospect, I probably should've stored this data in JSON rather than character delimited files.



# Data Cleaning




# Data Storage

(SQL etc.)




# Analysis

Load clean data:

```{r}
# THIS NEEDS TO BE IMPORTED FROM SQL TABLE!
df <- read.csv('../data/clean/clean.tsv', sep='\t', stringsAsFactors=FALSE)
```

[Joel section]



## Analysis: By Salary

Another way we might evaluate the relative worth of data science skills is by comparing the salaries of these job offers. Unfortunately, most of these listings do not provide salaries, so we'll have to use a sample much smaller than the original.

First, we'll need to standardize the `metadata` column that seems to exist only for conveying salaries. To begin, we'll subset the dataset to only contain data with salary information. 

Most of the observations are blank, represented by `character(0)` or an empty string `''`. Those empty observations will be filtered out, as well as metadata that does not refer to salary (operationalized by _contains the dollar sign $_) as well as those offering only an hourly wage:

```{r}
del <- df$metadata[1]
salary <- df %>% filter(metadata != del, 
                        metadata != '',
                        str_detect(metadata, '\\$') == TRUE,
                        str_detect(metadata, 'hour') == FALSE)
```

This leaves a total of `r nrow(salary)` observations with salary information. It is presented in a variety of formats that will need to be cleaned:

```{r}
head(salary$metadata)
```

We'll use a function to extract the important data and discard the rest. Note that this function will convert ranges into their averages, e.g., '$100,000 - $110,000' will be converted to '$105,000'.

First, determine if the input string is a valid input. The function is designed to handle common textual representations of salaries, which most often include a dollar sign. If the string does not include a dollar sign, the function assumes the input is invalid and returns `NA`. Otherwise, the function determines if the string contains a salary range or a single salary, via the presence of ` - `. From there, it strips out unnecessary characters, and returns a numeric data type for salary.

```{r}

extract_salary <- function(s) {
    has_dollar_sign <- str_detect(s, '\\$')
    if (has_dollar_sign == FALSE) {
        return(NA)
    } else {
        
        contains_range <- str_detect(s, ' - ')
        
        if (contains_range == TRUE) {
            text_range <- unlist(str_extract_all(s, '\\$[0-9,]+'))
            numeric_range <- as.numeric(str_remove_all(text_range, ',|\\$'))
            return(mean(c(numeric_range[1], numeric_range[2])))
        } else {
            as_text <- str_extract_all(s, '\\$[0-9,]+')
            as_numeric <- as.numeric(str_remove_all(as_text, ',|\\$'))
            return(as_numeric)
        }
    }
}
```

Run a few tests:

```{r}
extract_salary('This is not a salary')
extract_salary('$150,000 (depending on experience)')
extract_salary('$100,000 - $135,000')
```

Apply to our data frame with sapply:

```{r}
salary$salary <- as.numeric(lapply(salary$metadata, extract_salary))
head(salary$salary)
```

### Exploratoy Analysis

With our salary data now available, we can begin examining the distribution of salary and its variation across various dimensions.

```{r}
ggplot(salary, aes(salary)) + 
    geom_histogram(binwidth=10000)
```

The salary distribution has a clear central tendancy, though the distribution is pretty wide. We believe the data suggests that a larger sample size would raise several observations further to the right of the above distribution.

The 50th percentile data scientist salary is around $115,000. The minimum paying job is a Data Scientist position for Biz2Credit Inc. in New York City, while the max paying job is for a Senior Data Scientist position for Octane Lending, also in New York City.

```{r}
quantile(salary$salary, c(0, .1, .25, .5, .75, .9, .95, .99))
```



### Skills by Salary

With clean salary and skills data, we are now equipped to examine the relative value each skill in an exact dollar amount. First, we'll look at soft skills, then hard skills, then we'll compare them in aggregate.

Rearrange skills data to be amenable to analysis:

```{r}
skills_long <- salary %>%
    select(url, salary, city, softskill_communication:hardskill_shell) %>%
    gather(skill_name, skill, softskill_communication:hardskill_shell, factor_key=TRUE) %>%
    filter(skill == TRUE) %>%
    select(url, salary, city, skill_name)
```

#### Soft Skills

Further rearrange for soft-skills:

```{r}
soft_skills <- skills_long %>% 
    filter(str_detect(skill_name, 'softskill') == TRUE) %>%
    mutate(skill_name = str_remove(skill_name, 'softskill_')) %>%
    arrange(desc(salary))
```

Graphically represent this data with a box plot:

```{r}
ggplot(soft_skills, aes(skill_name, salary)) +
    geom_boxplot() +
    theme(axis.text.x=element_text(angle=45, hjust=1))
```

The graph gives a sense of the distribution of salaries corresponding to each skill. Below gives the mean value. We see time management appears to be most highly prized, with a mean salary of $120,500. 

```{r}
soft_skills %>% 
    group_by(skill_name) %>% 
    summarize(avg_salary=mean(salary)) %>%
    arrange(desc(avg_salary))
```

Surprisingly, leadership---a ubiquitous and often obnoxious buzzword of the corporate world---does not appear to be so highly valued for data scientists, with a mean salary of $90,000, and a 'lower distribution' than all the other soft skills.



#### Hard Skills

Duplicating this same analysis for hard skills:

```{r}
hard_skills <- skills_long %>% 
    filter(str_detect(skill_name, 'hardskill') == TRUE) %>%
    mutate(skill_name = str_remove(skill_name, 'hardskill_')) %>%
    arrange(desc(salary))

ggplot(hard_skills, aes(skill_name, salary)) +
    geom_boxplot() +
    theme(axis.text.x=element_text(angle=45, hjust=1))
```

The table gives the mean salary of each hard skill:

```{r}
hard_skills %>% 
    group_by(skill_name) %>% 
    summarize(avg_salary=mean(salary)) %>%
    arrange(desc(avg_salary))
```

Although the larger number of hard skills make the graph harder to read, there are perhaps three identifiable groups of higher-, medium-, and lesser-valued skills.

Among the top five most highly valued skills include Tensforflow, SQL, data mining, Hive, and Python. This makes sense to me---Tensorflow and deep learning are probably the greatest trend in data science today. Python and SQL are mainstays in data science, and Hive is probably the easiest way to access big data (in a SQL-like language) available today.

We are not unsurprised to see that Pig is among the lowest paid hard skill. Pig was Yahoo!'s answer to Hive, and never really caught on as well. Neither are we unsurprised that 'pivot table' is not valued so highly---data scientists are not Excel jockeys.

More surprising is that the average salary for R is less than $100,000. Though perhaps not---as Python catches up and (arguably) surpasses R as the langauge of choice for datas science, R would be valued less. Perhaps a flood of new R-trained data science and statistics graduates are depressing its price in the market!



#### Hard Skills v. Soft Skills

The following section is a small experiment to compare the value of soft and hard skills to employers. We will collect all soft skills and hard skills together, and examine their respective mean salaries.

```{r}
hard_soft <- skills_long %>%
    mutate(skill_type = ifelse(str_detect(skills_long$skill_name, 'softskill_') == TRUE, 'soft', 'hard')) %>%
    arrange(desc(salary))

ggplot(hard_soft, aes(skill_type, salary)) +
    geom_boxplot() +
    theme(axis.text.x=element_text(angle=45, hjust=1))
```

Although the mean salary for hard skills is slightly higher than soft skills, the distributions are effectively the same (at least for this low $n = 22$), both in terms of central tendency and variance.

```{r}
hard_soft %>% 
    group_by(skill_type) %>% 
    summarize(avg_salary=mean(salary)) %>%
    arrange(desc(avg_salary))
```

According to this data, we have to conclude that soft and hard skills are valued about equally by employers.


# Conclusion

[Sum conclusions]

[Note that these conclusions are based on a small sample size, and could be validated by collecting more data and re-running the analysis]

